### 2024.03.19
## 딥러닝의 기초 : 선형 회귀
y=wx+b</br>
w : weight</br>
b : bias</br>
1차 목표 : 학습 데이터를 통해 최적의 w와 b를 구하는 것</br>
최종 목표 : 내가 원하는 데이터에 상응하는 값을 구하는 것</br>

선형 그래프와 데이터 사이의 정사각형 넓이 -> Square Error</br>
Square error(mse)의 평균이 최소인 선형 함수가 최적</br>
